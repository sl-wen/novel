#!/usr/bin/env python3
"""
é€šç”¨ä¹¦æºæµ‹è¯•è„šæœ¬
- æŒ‰ä¹¦æºIDæˆ–åç§°æµ‹è¯•æœç´¢
- å±•ç¤ºæœç´¢ç»“æœã€è¯¦æƒ…é¡µã€ç›®å½•æ¦‚è§ˆ
- å¯é€‰è§¦å‘ä¸‹è½½(txt/epub)ï¼Œè¾“å‡ºä¸‹è½½æ–‡ä»¶è·¯å¾„

ç”¨æ³•ç¤ºä¾‹ï¼š
  python source_tester.py --keyword æ–—ç ´ --source-id 8 --max-results 5 --show-toc 10
  python source_tester.py --keyword é®å¤© --source-name å¤§ç†ŠçŒ«æ–‡å­¦ --download txt
  python source_tester.py --keyword å®Œç¾ä¸–ç•Œ --max-results 10  # è·¨ä¹¦æºæœç´¢
"""

import argparse
import asyncio
import contextlib
import logging
import sys
import time
from pathlib import Path

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent))

from app.parsers.search_parser import SearchParser
from app.services.novel_service import NovelService

# Windows å¹³å°ï¼šä½¿ç”¨ Selector äº‹ä»¶å¾ªç¯ç­–ç•¥ï¼Œé¿å…é€€å‡ºæ—¶ Proactor å™ªå£°
if sys.platform.startswith("win"):
    try:
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    except Exception:
        pass


def build_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="ä¹¦æºæœç´¢/ä¸‹è½½æµ‹è¯•å·¥å…·")
    parser.add_argument("--keyword", required=True, help="æœç´¢å…³é”®è¯")
    parser.add_argument("--source-id", type=int, help="ä¹¦æºIDï¼ˆä¼˜å…ˆäºåç§°ï¼‰")
    parser.add_argument("--source-name", type=str, help="ä¹¦æºåç§°ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰")
    parser.add_argument(
        "--max-results", type=int, default=5, help="å±•ç¤ºçš„æœ€å¤§æœç´¢ç»“æœæ•°"
    )
    parser.add_argument("--show-toc", type=int, default=8, help="å±•ç¤ºç›®å½•å‰Nç« ")
    parser.add_argument(
        "--download",
        choices=["none", "txt", "epub"],
        default="none",
        help="æ˜¯å¦ä¸‹è½½åŠä¸‹è½½æ ¼å¼",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="è¾“å‡ºè¯¦ç»†æ—¥å¿—ï¼ˆé»˜è®¤ä»…æ˜¾ç¤ºé”™è¯¯ï¼‰",
    )
    parser.add_argument(
        "--summary-only",
        action="store_true",
        help="ä»…è¾“å‡ºæ±‡æ€»è¡¨æ ¼ï¼ˆä¸è¿›è¡Œåç»­è¯¦ç»†æµ‹è¯•ï¼‰",
    )
    parser.add_argument(
        "--no-summary",
        action="store_true",
        help="è·³è¿‡å¼€å¤´çš„æ±‡æ€»è¡¨æ ¼",
    )
    return parser.parse_args()


def _configure_logging(verbose: bool) -> None:
    # åŸºç¡€é…ç½®ï¼šé»˜è®¤ä»…æ˜¾ç¤ºERRORï¼Œé¿å…å¹²æ‰°æµ‹è¯•è¾“å‡º
    logging.basicConfig(
        level=logging.ERROR, format="%(levelname)s - %(name)s - %(message)s"
    )

    # æŠ‘åˆ¶é¡¹ç›®å†…ä¸ç¬¬ä¸‰æ–¹çš„å†—ä½™æ—¥å¿—
    targets = [
        "app",
        "app.services.novel_service",
        "app.parsers.search_parser",
        "aiohttp",
        "asyncio",
    ]
    for name in targets:
        logging.getLogger(name).setLevel(logging.ERROR)

    if verbose:
        # æ‰“å¼€è¯¦ç»†æ—¥å¿—
        logging.getLogger().setLevel(logging.INFO)
        for name in targets:
            logging.getLogger(name).setLevel(logging.INFO)


async def search_in_specific_source(
    service: NovelService, source_id: int, keyword: str
):
    source = service.sources.get(source_id)
    if not source:
        raise ValueError(f"ä¹¦æºIDä¸å­˜åœ¨: {source_id}")
    parser = SearchParser(source)
    start = time.time()
    results = await parser.parse(keyword)
    elapsed = (time.time() - start) * 1000
    return results, elapsed, source.rule.get("name", f"ä¹¦æº{source_id}")


async def search_across_sources(service: NovelService, keyword: str, max_results: int):
    start = time.time()
    results = await service.search(keyword, max_results=max_results)
    elapsed = (time.time() - start) * 1000
    return results, elapsed


@contextlib.contextmanager
def suppress_logs(enable: bool):
    if not enable:
        # ä¸æŠ‘åˆ¶
        yield
        return
    prev = logging.root.manager.disable
    logging.disable(logging.CRITICAL)
    try:
        yield
    finally:
        logging.disable(prev)


async def summarize_all_sources(
    service: NovelService,
    keyword: str,
    max_results: int = 3,
    test_toc: bool = True,
    timeout_sec: int = 12,
    concurrency: int = 6,
    quiet: bool = True,
):
    """è¾“å‡ºæ‰€æœ‰ä¹¦æºçš„èƒ½åŠ›è¡¨æ ¼ï¼šå¯æœç´¢/å¯è·å–ç›®å½•/å¯ä¸‹è½½(åŸºäºè§„åˆ™)"""
    sources = service.sources
    sem = asyncio.Semaphore(concurrency)

    async def check_source(source_id: int, source) -> dict:
        async with sem:
            rule = source.rule
            name = rule.get("name", f"ä¹¦æº{source_id}")
            search_ok = False
            toc_ok = False
            result_count = 0
            elapsed_ms = 0
            with suppress_logs(quiet):
                try:
                    sp = SearchParser(source)
                    start = time.time()
                    results = await asyncio.wait_for(
                        sp.parse(keyword), timeout=timeout_sec
                    )
                    elapsed_ms = int((time.time() - start) * 1000)
                    result_count = len(results) if results else 0
                    search_ok = result_count > 0
                    if search_ok and test_toc:
                        first = results[0]
                        url = getattr(first, "url", "")
                        if url:
                            try:
                                toc = await asyncio.wait_for(
                                    service.get_toc(url, source_id), timeout=timeout_sec
                                )
                                toc_ok = bool(toc)
                            except Exception:
                                toc_ok = False
                except Exception:
                    search_ok = False
                    toc_ok = False

            return {
                "id": source_id,
                "name": name,
                "search": search_ok,
                "toc": toc_ok,
                "results": result_count,
                "time": elapsed_ms,
            }

    tasks = [check_source(sid, src) for sid, src in sources.items()]
    rows = await asyncio.gather(*tasks)

    # æ‰“å°è¡¨æ ¼
    print("\næ‰€æœ‰ä¹¦æºèƒ½åŠ›æ¦‚è§ˆï¼š")
    header = ["ID", "ä¹¦æº", "å¯æœç´¢", "å¯è·å–ç›®å½•", "ç»“æœæ•°", "è€—æ—¶(ms)"]
    print("-" * 80)
    print(
        f"{header[0]:<4} {header[1]:<16} {header[2]:<6} {header[3]:<10} {header[4]:<6} {header[5]:<6} "
    )
    print("-" * 80)
    for r in sorted(rows, key=lambda x: x["id"]):
        s = "âœ…" if r["search"] else "âŒ"
        t = "âœ…" if r["toc"] else "âŒ"
        print(
            f"{r['id']:<4} {r['name']:<16} {s:<6} {t:<10} {r['results']:<6} {r['time']:<9}"
        )
    print("-" * 80)

    return rows


async def main():
    args = build_args()

    # é…ç½®æ—¥å¿—çº§åˆ«
    _configure_logging(args.verbose)

    service = NovelService()

    # é¦–å…ˆè¾“å‡ºæ‰€æœ‰ä¹¦æºèƒ½åŠ›è¡¨æ ¼ï¼ˆé™¤éæ˜¾å¼è·³è¿‡ï¼‰
    if not args.no_summary:
        await summarize_all_sources(
            service,
            args.keyword,
            max_results=args.max_results,
            test_toc=True,
            quiet=not args.verbose,
        )
        if args.summary_only:
            print("\n(ä»…è¾“å‡ºæ±‡æ€»è¡¨æ ¼ï¼Œå·²ç»“æŸ)\n")
            return

    # è§£æç›®æ ‡ä¹¦æº
    target_source_id = None
    if args.source_id is not None:
        target_source_id = args.source_id
    elif args.source_name:
        # ç®€å•æ¨¡ç³ŠåŒ¹é…åç§° -> å–ç¬¬ä¸€ä¸ª
        for sid, src in service.sources.items():
            name = src.rule.get("name", str(sid))
            if args.source_name in name:
                target_source_id = sid
                break
        if target_source_id is None:
            raise ValueError(f"æœªæ‰¾åˆ°åŒ¹é…çš„ä¹¦æºåç§°: {args.source_name}")

    print("=" * 80)
    print(f"ğŸ” å…³é”®è¯: {args.keyword}")
    if target_source_id is not None:
        print(
            f"ğŸ¯ æŒ‡å®šä¹¦æº: {service.sources[target_source_id].rule.get('name', target_source_id)} (ID: {target_source_id})"
        )
    else:
        print("ğŸŒ è·¨ä¹¦æºæœç´¢æ¨¡å¼")
    print("=" * 80)

    # æ‰§è¡Œæœç´¢
    if target_source_id is not None:
        results, elapsed_ms, source_name = await search_in_specific_source(
            service, target_source_id, args.keyword
        )
        print(
            f"âœ… æœç´¢å®Œæˆï¼ˆ{source_name}ï¼‰ï¼š{len(results)} æ¡ï¼Œç”¨æ—¶ {elapsed_ms:.0f} ms"
        )
    else:
        results, elapsed_ms = await search_across_sources(
            service, args.keyword, args.max_results
        )
        print(f"âœ… æœç´¢å®Œæˆï¼ˆè·¨ä¹¦æºï¼‰ï¼š{len(results)} æ¡ï¼Œç”¨æ—¶ {elapsed_ms:.0f} ms")

    if not results:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç»“æœ")
        return

    print("\nå‰Næ¡ç»“æœï¼š")
    for i, r in enumerate(results[: args.max_results]):
        # SearchResult æ˜¯ pydantic BaseModel
        try:
            title = getattr(r, "title", "N/A")
            author = getattr(r, "author", "N/A")
            url = getattr(r, "url", "")
            src_id = getattr(r, "source_id", 0)
            src_name = getattr(r, "source_name", "")
            print(
                f"  {i+1}. {title} - {author} [{src_name or 'N/A'}#{src_id}]\n     {url}"
            )
        except Exception as e:
            print(f"  {i+1}. è§£æç»“æœå¤±è´¥: {e}")

    # é€‰å®šç”¨äºè¯¦æƒ…/ç›®å½•/ä¸‹è½½çš„ç›®æ ‡ç»“æœ
    chosen = results[0]
    book_url = getattr(chosen, "url", "")
    book_source_id = getattr(chosen, "source_id", target_source_id or 0)
    book_source_name = getattr(chosen, "source_name", "")

    if not book_url or not book_source_id:
        print("âš ï¸ æ— æ³•è§£æåˆ°æœ‰æ•ˆçš„è¯¦æƒ…URLæˆ–ä¹¦æºIDï¼Œè·³è¿‡è¯¦æƒ…/ç›®å½•/ä¸‹è½½")
        return

    print("\n" + "-" * 80)
    print(f"ğŸ“„ è¯¦æƒ…ä¸ç›®å½•ï¼ˆæ¥æºï¼š{book_source_name or book_source_id}ï¼‰")
    # è·å–è¯¦æƒ…
    detail_start = time.time()
    book = await service.get_book_detail(book_url, book_source_id)
    detail_ms = (time.time() - detail_start) * 1000
    if book:
        print(f"âœ… è·å–è¯¦æƒ…æˆåŠŸï¼Œç”¨æ—¶ {detail_ms:.0f} ms")
        # ä¹¦åå…œåº•ï¼šè¯¦æƒ…é¡µç¼ºå¤±æ—¶å›é€€ä¸ºæœç´¢ç»“æœæ ‡é¢˜
        fallback_title = getattr(chosen, "title", "N/A")
        book_title = getattr(book, "name", "") or fallback_title
        print(f"   ä¹¦å: {book_title}  ä½œè€…: {getattr(book, 'author', 'N/A')}")
        intro = getattr(book, "intro", "") or ""
        if intro:
            intro_short = intro.strip().replace("\n", " ")[:100]
            print(f"   ç®€ä»‹: {intro_short}{'â€¦' if len(intro) > 100 else ''}")
    else:
        print(f"âŒ è·å–è¯¦æƒ…å¤±è´¥ï¼Œç”¨æ—¶ {detail_ms:.0f} ms")

    # è·å–ç›®å½•
    toc_start = time.time()
    toc = await service.get_toc(book_url, book_source_id)
    toc_ms = (time.time() - toc_start) * 1000
    print(f"ğŸ“š ç›®å½•ç« èŠ‚: {len(toc)} æ¡ï¼Œç”¨æ—¶ {toc_ms:.0f} ms")
    for i, ch in enumerate(toc[: args.show_toc]):
        try:
            print(
                f"   - {i+1}. {getattr(ch, 'title', 'N/A')}  ({getattr(ch, 'url', '')})"
            )
        except Exception:
            pass

    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ")

    # ä¼˜é›…å…³é—­å…¨å±€HTTPå®¢æˆ·ç«¯ï¼Œé¿å…æœªå…³é—­çš„session/connectorå‘Šè­¦
    try:
        await service.http_client.shutdown()
    except Exception:
        pass


if __name__ == "__main__":
    asyncio.run(main())
