#!/usr/bin/env python3
"""
æ›´è¯¦ç»†çš„ç›®å½•è§£æå™¨è°ƒè¯•
"""

import requests
import json
import urllib.request
from bs4 import BeautifulSoup

def debug_toc_detailed():
    """æ›´è¯¦ç»†çš„ç›®å½•è§£æå™¨è°ƒè¯•"""
    print("ğŸ” æ›´è¯¦ç»†çš„ç›®å½•è§£æå™¨è°ƒè¯•...")
    
    # 1. ç›´æ¥è®¿é—®ç½‘ç«™è·å–HTML
    print("1. ç›´æ¥è®¿é—®ç½‘ç«™è·å–HTML...")
    try:
        url = "https://www.0xs.net/txt/1.html"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # åˆ›å»ºSSLä¸Šä¸‹æ–‡ï¼Œè·³è¿‡è¯ä¹¦éªŒè¯
        import ssl
        context = ssl.create_default_context()
        context.check_hostname = False
        context.verify_mode = ssl.CERT_NONE
        
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req, context=context, timeout=30) as response:
            html = response.read().decode('utf-8')
            print(f"   âœ… ç½‘ç«™è®¿é—®æˆåŠŸï¼ŒHTMLé•¿åº¦: {len(html)}")
            
            # 2. åˆ†æHTMLç»“æ„
            print("\n2. åˆ†æHTMLç»“æ„...")
            soup = BeautifulSoup(html, "html.parser")
            
            # æ£€æŸ¥æ–°çš„é€‰æ‹©å™¨
            selector = ".catalog li a"
            elements = soup.select(selector)
            print(f"   - æ–°é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
            
            if elements:
                print("   - å‰5ä¸ªå…ƒç´ :")
                for i, elem in enumerate(elements[:5]):
                    text = elem.get_text(strip=True)
                    href = elem.get('href', '')
                    print(f"     {i+1}. {text} -> {href}")
            
            # 3. æ£€æŸ¥ç›®å½•å®¹å™¨ç»“æ„
            print("\n3. æ£€æŸ¥ç›®å½•å®¹å™¨ç»“æ„...")
            catalog = soup.select_one('.catalog')
            if catalog:
                print("   - æ‰¾åˆ° .catalog å®¹å™¨")
                print(f"   - å®¹å™¨HTML: {str(catalog)[:200]}...")
                
                # æ£€æŸ¥å®¹å™¨å†…çš„æ‰€æœ‰é“¾æ¥
                all_links = catalog.find_all('a')
                print(f"   - å®¹å™¨å†…æ€»å…±æœ‰ {len(all_links)} ä¸ªé“¾æ¥")
                
                # è¿‡æ»¤å‡ºç« èŠ‚é“¾æ¥
                chapter_links = []
                for link in all_links:
                    href = link.get('href', '')
                    text = link.get_text(strip=True)
                    if '/txt/' in href and text:
                        chapter_links.append({
                            'text': text,
                            'href': href
                        })
                
                print(f"   - æ‰¾åˆ° {len(chapter_links)} ä¸ªç« èŠ‚é“¾æ¥")
                for i, link in enumerate(chapter_links[:10]):
                    print(f"     {i+1}. {link['text']} -> {link['href']}")
            else:
                print("   âŒ æœªæ‰¾åˆ° .catalog å®¹å™¨")
            
            # 4. æ¨¡æ‹Ÿç›®å½•è§£æå™¨é€»è¾‘
            print("\n4. æ¨¡æ‹Ÿç›®å½•è§£æå™¨é€»è¾‘...")
            
            # æ¨¡æ‹Ÿ _parse_single_chapter æ–¹æ³•
            def parse_single_chapter(element, order):
                try:
                    # è·å–ç« èŠ‚æ ‡é¢˜
                    title = element.get_text(strip=True)
                    
                    # è·å–ç« èŠ‚URL
                    url = element.get('href', '')
                    
                    # æ„å»ºå®Œæ•´URL
                    if url and not url.startswith(("http://", "https://")):
                        base_url = "https://www.0xs.net"
                        url = f"{base_url.rstrip('/')}/{url.lstrip('/')}"
                    
                    return {
                        'title': title or f"ç¬¬{order}ç« ",
                        'url': url or "",
                        'order': order
                    }
                except Exception as e:
                    print(f"     âŒ è§£æç« èŠ‚å¤±è´¥: {str(e)}")
                    return None
            
            # è§£ææ‰€æœ‰æ‰¾åˆ°çš„å…ƒç´ 
            parsed_chapters = []
            for i, elem in enumerate(elements, 1):
                chapter = parse_single_chapter(elem, i)
                if chapter:
                    parsed_chapters.append(chapter)
            
            print(f"   - æˆåŠŸè§£æ {len(parsed_chapters)} ä¸ªç« èŠ‚")
            for i, chapter in enumerate(parsed_chapters[:5]):
                print(f"     {i+1}. {chapter['title']} -> {chapter['url']}")
            
            # 5. æ£€æŸ¥APIå“åº”
            print("\n5. æ£€æŸ¥APIå“åº”...")
            try:
                base_url = "http://localhost:8000"
                response = requests.get(
                    f"{base_url}/api/novels/toc",
                    params={
                        "url": "https://www.0xs.net/txt/1.html",
                        "sourceId": 11
                    },
                    timeout=60
                )
                
                print(f"   - APIçŠ¶æ€ç : {response.status_code}")
                if response.status_code == 200:
                    data = response.json()
                    chapters = data.get("data", [])
                    print(f"   - APIè¿”å›ç« èŠ‚æ•°: {len(chapters)}")
                    
                    if chapters:
                        print("   - å‰5ä¸ªç« èŠ‚:")
                        for i, chapter in enumerate(chapters[:5]):
                            print(f"     {i+1}. {chapter.get('title', 'Unknown')} -> {chapter.get('url', 'Unknown')}")
                    else:
                        print("   âŒ APIè¿”å›ç©ºç« èŠ‚åˆ—è¡¨")
                else:
                    print(f"   - APIé”™è¯¯: {response.text}")
                    
            except Exception as e:
                print(f"   âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}")
            
            # 6. ç”Ÿæˆä¿®å¤å»ºè®®
            print("\n6. ç”Ÿæˆä¿®å¤å»ºè®®...")
            if parsed_chapters:
                print("   âœ… æœ¬åœ°è§£ææˆåŠŸï¼ŒAPIå¯èƒ½æœ‰é—®é¢˜")
                print("   ğŸ’¡ å»ºè®®æ£€æŸ¥:")
                print("   - ç›®å½•è§£æå™¨çš„ç½‘ç»œè¯·æ±‚")
                print("   - ç›®å½•è§£æå™¨çš„é”™è¯¯å¤„ç†")
                print("   - ç›®å½•è§£æå™¨çš„æ—¥å¿—è¾“å‡º")
            else:
                print("   âŒ æœ¬åœ°è§£æä¹Ÿå¤±è´¥")
                print("   ğŸ’¡ å»ºè®®æ£€æŸ¥:")
                print("   - ç½‘ç«™HTMLç»“æ„")
                print("   - CSSé€‰æ‹©å™¨")
                print("   - ç½‘ç»œè¯·æ±‚")
                
    except Exception as e:
        print(f"   âŒ ç½‘ç«™è®¿é—®å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    debug_toc_detailed()