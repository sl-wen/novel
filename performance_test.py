#!/usr/bin/env python3
"""
å¹¶è¡Œä¸‹è½½æ€§èƒ½æµ‹è¯•å·¥å…·

æµ‹è¯•å’Œå¯¹æ¯”ä¼˜åŒ–å‰åçš„ä¸‹è½½æ€§èƒ½ï¼Œåˆ†ææ€§èƒ½æ”¹è¿›æ•ˆæœ
"""

import asyncio
import sys
import time
from pathlib import Path
from typing import Dict, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from app.core.source import Source
from app.core.crawler import Crawler, DownloadConfig
from app.parsers.toc_parser import TocParser


class PerformanceTestRunner:
    """æ€§èƒ½æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.test_results = []
    
    async def run_performance_test(self, source_id: int, url: str, test_name: str = "é»˜è®¤æµ‹è¯•"):
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        print(f"\nğŸš€ å¼€å§‹æ€§èƒ½æµ‹è¯•: {test_name}")
        print("=" * 60)
        
        try:
            # åˆ›å»ºä¹¦æºå’Œè§£æå™¨
            source = Source(source_id)
            parser = TocParser(source)
            
            print(f"ğŸ“š ä¹¦æº: {source.name}")
            print(f"ğŸ”— URL: {url}")
            
            # è·å–ç›®å½•
            print("\nâ³ è·å–ç›®å½•...")
            toc_start = time.time()
            chapters = await parser.parse(url)
            toc_time = time.time() - toc_start
            
            if not chapters:
                print("âŒ æœªè·å–åˆ°ç« èŠ‚")
                return None
            
            print(f"âœ… è·å–åˆ° {len(chapters)} ä¸ªç« èŠ‚ (è€—æ—¶: {toc_time:.2f}s)")
            
            # æµ‹è¯•ä¸åŒçš„ä¸‹è½½é…ç½®
            test_configs = [
                ("ä¿å®ˆé…ç½®", DownloadConfig(
                    max_concurrent=5,
                    retry_times=3,
                    retry_delay=1.0,
                    batch_delay=0.5,
                    timeout=30,
                    enable_batch_write=False,
                    skip_quality_check=False
                )),
                ("å¹³è¡¡é…ç½®", DownloadConfig(
                    max_concurrent=10,
                    retry_times=3,
                    retry_delay=0.5,
                    batch_delay=0.2,
                    timeout=30,
                    enable_batch_write=True,
                    skip_quality_check=False
                )),
                ("æ¿€è¿›é…ç½®", DownloadConfig(
                    max_concurrent=15,
                    retry_times=2,
                    retry_delay=0.3,
                    batch_delay=0.1,
                    timeout=20,
                    enable_batch_write=True,
                    skip_quality_check=True
                ))
            ]
            
            results = []
            
            for config_name, config in test_configs:
                print(f"\nğŸ“Š æµ‹è¯•é…ç½®: {config_name}")
                print(f"   å¹¶å‘æ•°: {config.max_concurrent}")
                print(f"   é‡è¯•æ¬¡æ•°: {config.retry_times}")
                print(f"   æ‰¹é‡å†™å…¥: {'å¯ç”¨' if config.enable_batch_write else 'ç¦ç”¨'}")
                print(f"   è´¨é‡æ£€æŸ¥: {'è·³è¿‡' if config.skip_quality_check else 'å¯ç”¨'}")
                
                # é™åˆ¶æµ‹è¯•ç« èŠ‚æ•°é‡ä»¥åŠ å¿«æµ‹è¯•
                test_chapters = chapters[:min(20, len(chapters))]
                
                result = await self._test_download_performance(
                    source_id, test_chapters, config, config_name
                )
                
                if result:
                    results.append(result)
                    self._print_test_result(result)
            
            # å¯¹æ¯”ç»“æœ
            if len(results) > 1:
                self._compare_results(results)
            
            return results
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    async def _test_download_performance(
        self, source_id: int, chapters: List, config: DownloadConfig, config_name: str
    ) -> Dict:
        """æµ‹è¯•ä¸‹è½½æ€§èƒ½"""
        from app.parsers.chapter_parser import ChapterParser
        
        print(f"   â³ å¼€å§‹ä¸‹è½½ {len(chapters)} ä¸ªç« èŠ‚...")
        
        start_time = time.time()
        
        source = Source(source_id)
        parser = ChapterParser(source)
        
        # æ¨¡æ‹Ÿä¸‹è½½è¿‡ç¨‹
        successful_downloads = 0
        failed_downloads = 0
        total_content_length = 0
        download_times = []
        
        # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘
        semaphore = asyncio.Semaphore(config.max_concurrent)
        
        async def download_chapter(chapter_info):
            nonlocal successful_downloads, failed_downloads, total_content_length
            
            async with semaphore:
                chapter_start = time.time()
                
                try:
                    # æ¨¡æ‹Ÿä¸‹è½½å»¶è¿Ÿ
                    if config.batch_delay > 0:
                        await asyncio.sleep(config.batch_delay)
                    
                    chapter = await asyncio.wait_for(
                        parser.parse(chapter_info.url, chapter_info.title, chapter_info.order),
                        timeout=config.timeout
                    )
                    
                    if chapter and chapter.content:
                        download_time = time.time() - chapter_start
                        download_times.append(download_time)
                        successful_downloads += 1
                        total_content_length += len(chapter.content)
                    else:
                        failed_downloads += 1
                        
                except Exception as e:
                    failed_downloads += 1
                    print(f"     âš ï¸ ç« èŠ‚ä¸‹è½½å¤±è´¥: {chapter_info.title}")
        
        # å¹¶å‘ä¸‹è½½
        tasks = [download_chapter(ch) for ch in chapters]
        await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        success_rate = successful_downloads / len(chapters) if chapters else 0
        avg_download_time = sum(download_times) / len(download_times) if download_times else 0
        download_speed = successful_downloads / total_time if total_time > 0 else 0
        avg_content_length = total_content_length / successful_downloads if successful_downloads > 0 else 0
        
        return {
            "config_name": config_name,
            "config": config,
            "total_chapters": len(chapters),
            "successful_downloads": successful_downloads,
            "failed_downloads": failed_downloads,
            "total_time": total_time,
            "success_rate": success_rate,
            "avg_download_time": avg_download_time,
            "download_speed": download_speed,
            "total_content_length": total_content_length,
            "avg_content_length": avg_content_length
        }
    
    def _print_test_result(self, result: Dict):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print(f"   âœ… æµ‹è¯•å®Œæˆ:")
        print(f"      æ€»ç« èŠ‚: {result['total_chapters']}")
        print(f"      æˆåŠŸ: {result['successful_downloads']}")
        print(f"      å¤±è´¥: {result['failed_downloads']}")
        print(f"      æˆåŠŸç‡: {result['success_rate']:.1%}")
        print(f"      æ€»è€—æ—¶: {result['total_time']:.2f}s")
        print(f"      å¹³å‡ä¸‹è½½æ—¶é—´: {result['avg_download_time']:.2f}s")
        print(f"      ä¸‹è½½é€Ÿåº¦: {result['download_speed']:.2f} ç« /ç§’")
        print(f"      å¹³å‡ç« èŠ‚é•¿åº¦: {result['avg_content_length']:.0f} å­—ç¬¦")
    
    def _compare_results(self, results: List[Dict]):
        """å¯¹æ¯”æµ‹è¯•ç»“æœ"""
        print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”åˆ†æ")
        print("=" * 60)
        
        # æ‰¾å‡ºæœ€ä½³é…ç½®
        best_speed = max(results, key=lambda x: x['download_speed'])
        best_success = max(results, key=lambda x: x['success_rate'])
        
        print(f"ğŸ† æœ€å¿«ä¸‹è½½é€Ÿåº¦: {best_speed['config_name']} ({best_speed['download_speed']:.2f} ç« /ç§’)")
        print(f"ğŸ¯ æœ€é«˜æˆåŠŸç‡: {best_success['config_name']} ({best_success['success_rate']:.1%})")
        
        # è¯¦ç»†å¯¹æ¯”è¡¨
        print(f"\nğŸ“Š è¯¦ç»†å¯¹æ¯”:")
        print(f"{'é…ç½®åç§°':<12} {'æˆåŠŸç‡':<8} {'é€Ÿåº¦(ç« /s)':<10} {'å¹³å‡æ—¶é—´(s)':<12} {'æ€»è€—æ—¶(s)':<10}")
        print("-" * 60)
        
        for result in results:
            print(f"{result['config_name']:<12} "
                  f"{result['success_rate']:<8.1%} "
                  f"{result['download_speed']:<10.2f} "
                  f"{result['avg_download_time']:<12.2f} "
                  f"{result['total_time']:<10.2f}")
        
        # æ€§èƒ½æ”¹è¿›åˆ†æ
        if len(results) >= 2:
            baseline = results[0]  # ä¿å®ˆé…ç½®ä½œä¸ºåŸºçº¿
            best = max(results, key=lambda x: x['download_speed'])
            
            if best != baseline:
                speed_improvement = (best['download_speed'] - baseline['download_speed']) / baseline['download_speed'] * 100
                time_improvement = (baseline['total_time'] - best['total_time']) / baseline['total_time'] * 100
                
                print(f"\nğŸš€ æ€§èƒ½æ”¹è¿›:")
                print(f"   ä¸‹è½½é€Ÿåº¦æå‡: {speed_improvement:.1f}%")
                print(f"   æ€»æ—¶é—´å‡å°‘: {time_improvement:.1f}%")
                
                if speed_improvement > 50:
                    print("   ğŸ’¡ å»ºè®®: é‡‡ç”¨é«˜æ€§èƒ½é…ç½®å¯æ˜¾è‘—æå‡ä¸‹è½½é€Ÿåº¦")
                elif speed_improvement > 20:
                    print("   ğŸ’¡ å»ºè®®: å¹³è¡¡é…ç½®å¯åœ¨æ€§èƒ½å’Œç¨³å®šæ€§ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡")
                else:
                    print("   ğŸ’¡ å»ºè®®: ä¿å®ˆé…ç½®å¯èƒ½æ›´é€‚åˆå½“å‰ç½‘ç»œç¯å¢ƒ")
    
    def get_optimization_recommendations(self, results: List[Dict]) -> List[str]:
        """è·å–ä¼˜åŒ–å»ºè®®"""
        if not results:
            return []
        
        recommendations = []
        
        # åˆ†ææˆåŠŸç‡
        avg_success_rate = sum(r['success_rate'] for r in results) / len(results)
        if avg_success_rate < 0.8:
            recommendations.append("æ•´ä½“æˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œç›®æ ‡æœåŠ¡å™¨çŠ¶æ€")
        
        # åˆ†æä¸‹è½½é€Ÿåº¦
        speeds = [r['download_speed'] for r in results]
        if max(speeds) - min(speeds) > 2.0:
            recommendations.append("ä¸åŒé…ç½®é—´æ€§èƒ½å·®å¼‚è¾ƒå¤§ï¼Œå»ºè®®æ ¹æ®å®é™…æƒ…å†µé€‰æ‹©åˆé€‚çš„é…ç½®")
        
        # åˆ†æå¹¶å‘æ•ˆæœ
        concurrent_configs = [(r['config'].max_concurrent, r['download_speed']) for r in results]
        concurrent_configs.sort()
        
        if len(concurrent_configs) >= 2:
            low_concurrent = concurrent_configs[0]
            high_concurrent = concurrent_configs[-1]
            
            if high_concurrent[1] > low_concurrent[1] * 1.5:
                recommendations.append("å¢åŠ å¹¶å‘æ•°å¯æ˜¾è‘—æå‡æ€§èƒ½")
            elif high_concurrent[1] < low_concurrent[1]:
                recommendations.append("è¿‡é«˜çš„å¹¶å‘æ•°å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œå»ºè®®é€‚å½“é™ä½")
        
        return recommendations


async def main():
    """ä¸»å‡½æ•°"""
    print("å¹¶è¡Œä¸‹è½½æ€§èƒ½æµ‹è¯•å·¥å…·")
    print("====================")
    
    # é»˜è®¤æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "source_id": 4,
            "url": "http://wap.99xs.info/124310/",
            "name": "ä¹¦æº4æ€§èƒ½æµ‹è¯•"
        }
    ]
    
    runner = PerformanceTestRunner()
    
    for test_case in test_cases:
        results = await runner.run_performance_test(
            test_case["source_id"],
            test_case["url"],
            test_case["name"]
        )
        
        if results:
            recommendations = runner.get_optimization_recommendations(results)
            if recommendations:
                print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
                for i, rec in enumerate(recommendations, 1):
                    print(f"   {i}. {rec}")
        
        print("\n" + "="*60)


if __name__ == "__main__":
    asyncio.run(main())